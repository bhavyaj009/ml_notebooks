{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkyU6PsKTQST",
        "outputId": "13487d22-d4db-46b1-f2dc-21c95d3d52e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# prompt: get mnist data from web and put into data folder\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create the data directory if it doesn't exist\n",
        "data_dir = os.path.join(os.getcwd(), 'data')\n",
        "if not os.path.exists(data_dir):\n",
        "  os.makedirs(data_dir)\n",
        "\n",
        "# Download and extract the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Save the training and test data to the data directory\n",
        "np.save(os.path.join(data_dir, 'x_train.npy'), x_train)\n",
        "np.save(os.path.join(data_dir, 'y_train.npy'), y_train)\n",
        "np.save(os.path.join(data_dir, 'x_test.npy'), x_test)\n",
        "np.save(os.path.join(data_dir, 'y_test.npy'), y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load npy files and visualize in one row\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the data from the data directory\n",
        "x_train = np.load(os.path.join(data_dir, 'x_train.npy'))\n",
        "y_train = np.load(os.path.join(data_dir, 'y_train.npy'))\n",
        "x_test = np.load(os.path.join(data_dir, 'x_test.npy'))\n",
        "y_test = np.load(os.path.join(data_dir, 'y_test.npy'))\n",
        "\n",
        "# Plot the first n images in a row\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(n):\n",
        "  plt.subplot(1, n, i+1)\n",
        "  plt.imshow(x_train[i], cmap='gray')\n",
        "  plt.title(y_train[i])\n",
        "  plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "fDM2s4FcVs6U",
        "outputId": "b65fd162-99ef-48fc-e04e-b25591403dc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def add_occlusion(image):\n",
        "    x, y = np.random.randint(0, image.shape[0] - 10, 2)\n",
        "    image[x:x+10, y:y+10] = 0\n",
        "    return image\n",
        "\n",
        "def add_scratch(image):\n",
        "    scratch_length = np.random.randint(5, 10)\n",
        "    scratch_thickness = np.random.randint(1, 2)\n",
        "    start_x = np.random.randint(0, image.shape[0])\n",
        "    start_y = np.random.randint(0, image.shape[1])\n",
        "    end_x = (start_x + scratch_length) % image.shape[0]\n",
        "    end_y = (start_y + scratch_length) % image.shape[1]\n",
        "    cv2.line(image, (start_x, start_y), (end_x, end_y), (224,), scratch_thickness)\n",
        "    return image"
      ],
      "metadata": {
        "id": "n9ebtH5kV_Je"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = x_train.copy()\n",
        "print(len(train_data))\n",
        "num_augmentations = 1000\n",
        "indices = np.random.choice(train_data.shape[0], num_augmentations, replace=False)\n",
        "\n",
        "plt.figure(figsize=(20, 2))\n",
        "\n",
        "cnt = 1\n",
        "for i in indices:\n",
        "    train_data[i] = add_scratch(train_data[i])\n",
        "    plt.subplot(1, 10, cnt)\n",
        "    cnt = cnt + 1\n",
        "    plt.imshow(train_data[i], cmap='gray')\n",
        "    plt.title(y_train[i])\n",
        "    plt.axis('off')\n",
        "    if cnt>10:\n",
        "      break\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "d5JMuTtCWfJu",
        "outputId": "70e2a6ce-391e-4c47-9ce8-e514b975adcb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lV2y-Fq3i7KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# # Load MNIST data\n",
        "# (x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# # Normalize the data\n",
        "# x_train = x_train.astype('float32') / 255.\n",
        "# x_test = x_test.astype('float32') / 255.\n",
        "# x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "# x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "# # Define the input layer\n",
        "# input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# # Define the encoding layers\n",
        "# x = Flatten()(input_img)\n",
        "# x = Dense(128, activation='relu')(x)\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "# encoded = Dense(32, activation='relu')(x)\n",
        "\n",
        "# # Define the decoding layers\n",
        "# x = Dense(64, activation='relu')(encoded)\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "# x = Dense(128, activation='relu')(x)\n",
        "# x = Dense(28 * 28, activation='sigmoid')(x)\n",
        "# decoded = Reshape((28, 28, 1))(x)\n",
        "\n",
        "# # Define the autoencoder model\n",
        "# autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# # Compile the autoencoder model\n",
        "# autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "# # Train the autoencoder model\n",
        "# autoencoder.fit(x_train, x_train,\n",
        "#                 epochs=200,\n",
        "#                 batch_size=256,\n",
        "#                 shuffle=True,\n",
        "#                 validation_data=(x_test, x_test))\n",
        "\n",
        "# # Encode and decode some digits\n",
        "# encoded_digits = autoencoder.predict(x_test)\n",
        "\n",
        "# # Plot the original and decoded digits\n",
        "# n = 10\n",
        "# plt.figure(figsize=(20, 4))\n",
        "# for i in range(n):\n",
        "#     # Display original image\n",
        "#     ax = plt.subplot(2, n, i + 1)\n",
        "#     plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "#     ax.get_xaxis().set_visible(False)\n",
        "#     ax.get_yaxis().set_visible(False)\n",
        "\n",
        "#     # Display decoded image\n",
        "#     ax = plt.subplot(2, n, i + 1 + n)\n",
        "#     plt.imshow(encoded_digits[i].reshape(28, 28), cmap='gray')\n",
        "#     ax.get_xaxis().set_visible(False)\n",
        "#     ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "6cFf6Cx-ZRqZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load MNIST data\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "# Define the input layer\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# Define the encoding layers\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Define the decoding layers\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the autoencoder model\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                          epochs=50,\n",
        "                          batch_size=256,\n",
        "                          shuffle=True,\n",
        "                          validation_data=(x_test, x_test),\n",
        "                          callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "NwBY0-RYVHs6",
        "outputId": "b2424773-cf26-4e98-fafb-9c0c89c94594"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 13s 18ms/step - loss: 0.1733 - val_loss: 0.0873\n",
            "Epoch 2/50\n",
            "141/235 [=================>............] - ETA: 1s - loss: 0.0848"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5508a6f9994a>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Train the autoencoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m history = autoencoder.fit(x_train, x_train,\n\u001b[0m\u001b[1;32m     44\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load MNIST data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "# Define the autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2, padding=0),  # No padding\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2, padding=0)  # No padding\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(32, 1, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# Initialize the model, loss function and optimizer\n",
        "autoencoder = Autoencoder()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "# Train the autoencoder\n",
        "num_epochs = 20\n",
        "early_stopping_patience = 3\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    autoencoder.train()\n",
        "    train_loss = 0\n",
        "    for data in train_loader:\n",
        "        inputs, _ = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = autoencoder(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    autoencoder.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            inputs, _ = data\n",
        "            outputs = autoencoder(inputs)\n",
        "            loss = criterion(outputs, inputs)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(autoencoder.state_dict(), 'best_autoencoder.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= early_stopping_patience:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "# Load the best model\n",
        "autoencoder.load_state_dict(torch.load('best_autoencoder.pth'))\n",
        "\n",
        "# Plot some of the reconstructed images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "nLjESnmOkqLi",
        "outputId": "64281952-6d0d-413d-b186-98b4166cd294"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Train Loss: 0.1837, Validation Loss: 0.0882\n",
            "Epoch [2/20], Train Loss: 0.0846, Validation Loss: 0.0804\n",
            "Epoch [3/20], Train Loss: 0.0796, Validation Loss: 0.0771\n",
            "Epoch [4/20], Train Loss: 0.0770, Validation Loss: 0.0750\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-657895dd73f0>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-657895dd73f0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load MNIST data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define the Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, img_shape, code_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(img_shape[0], 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(256 * 3 * 3, code_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.conv1(x))\n",
        "        x = self.pool2(self.conv2(x))\n",
        "        x = self.pool3(self.conv3(x))\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, code_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc = nn.Linear(code_size, 256 * 3 * 3)\n",
        "        # Adjust parameters to correctly upsample to 28x28\n",
        "        self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2)\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, padding=1)\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 256, 3, 3)\n",
        "        x = self.deconv1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.deconv3(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# Define the Autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, img_shape, code_size):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder(img_shape, code_size)\n",
        "        self.decoder = Decoder(code_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "img_shape = (1, 28, 28)\n",
        "code_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = Autoencoder(img_shape, code_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for data in trainloader:\n",
        "        inputs, _ = data\n",
        "        outputs = model(inputs)\n",
        "        print(outputs.size())\n",
        "        loss = criterion(outputs, inputs)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'autoencoder.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "JBUs8HZp8FX5",
        "outputId": "7240bdba-bac3-42cc-f7a1-9d8a1149741d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 22, 22])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64, 1, 28, 28])) that is different to the input size (torch.Size([64, 1, 22, 22])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (22) must match the size of tensor b (28) at non-singleton dimension 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-558a569c618c>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3363\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3365\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (22) must match the size of tensor b (28) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.eval()\n",
        "with torch.no_grad():\n",
        "    data_iter = iter(test_loader)\n",
        "    inputs, _ = next(data_iter)\n",
        "    outputs = autoencoder(inputs)\n",
        "\n",
        "    inputs = inputs.numpy()\n",
        "    outputs = outputs.numpy()\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2)\n",
        "    axes[0].imshow(inputs[0].reshape(28, 28), cmap='gray')\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[1].imshow(outputs[0].reshape(28, 28), cmap='gray')\n",
        "    axes[1].set_title('Reconstructed Image')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "l98ZGdT06buZ",
        "outputId": "678e67d3-490f-4e88-d2a0-1032e3055b63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode and decode some digits\n",
        "decoded_digits = autoencoder.predict(x_test)\n",
        "\n",
        "# Plot the original and decoded digits\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original image\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display decoded image\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_digits[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "brZieOpYWiAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: select indices and make an nd array, indices is list and use current ndarray for selection\n",
        "\n",
        "# indices = [3, 4, 5]\n",
        "train_data = train_data[indices]\n"
      ],
      "metadata": {
        "id": "QxPZCJEMV_37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}