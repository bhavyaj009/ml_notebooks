{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from lightly import loss, transforms\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.models.modules import heads\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define SimCLR model\n",
    "class SimCLR(torch.nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = heads.SimCLRProjectionHead(\n",
    "            input_dim=512,  # Adjust based on backbone output\n",
    "            hidden_dim=512,\n",
    "            output_dim=128,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(features)\n",
    "        return z\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model and move to GPU if available\n",
    "backbone = torchvision.models.resnet18(pretrained=False)\n",
    "backbone.fc = torch.nn.Identity()\n",
    "model = SimCLR(backbone).to(device)\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "transform = transforms.SimCLRTransform(input_size=32)\n",
    "dataset = LightlyDataset(input_dir=\"./data/cifar-10/train/\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = loss.NTXentLoss(temperature=0.5).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-6)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for (view0, view1), _, _ in dataloader:\n",
    "        view0, view1 = view0.to(device), view1.to(device)\n",
    "        z0 = model(view0)\n",
    "        z1 = model(view1)\n",
    "        loss = criterion(z0, z1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(f\"Loss: {loss.item():.5f}\")\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(model, dataloader, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch[0].to(device)  # Assuming batch is a list of [images, labels]\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "    return np.vstack(features)\n",
    "\n",
    "# Extract features\n",
    "features = extract_features(model, dataloader, device)\n",
    "\n",
    "# Visualize selected images\n",
    "def visualize_selected_images(images, labels, selected_indices, image_size=(32, 32), grid_shape=(2, 5)):\n",
    "    fig, axs = plt.subplots(nrows=grid_shape[0], ncols=grid_shape[1], figsize=(15, 6))\n",
    "    axs = axs.flatten()\n",
    "    for ax, idx in zip(axs, selected_indices):\n",
    "        image = images[idx].reshape(image_size[0], image_size[1], 3)\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f\"Label: {labels[idx]}\")\n",
    "        ax.axis('off')\n",
    "    for ax in axs[len(selected_indices):]:\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# k-Center Greedy algorithm for uncertainty sampling\n",
    "def k_center_greedy(features, n_samples):\n",
    "    n_points = features.shape[0]\n",
    "    centers = [np.random.randint(n_points)]\n",
    "    distances = pairwise_distances(features, features[centers]).flatten()\n",
    "    for _ in range(1, n_samples):\n",
    "        new_center = np.argmax(distances)\n",
    "        centers.append(new_center)\n",
    "        new_distances = pairwise_distances(features, features[new_center].reshape(1, -1)).flatten()\n",
    "        distances = np.minimum(distances, new_distances)\n",
    "    return centers\n",
    "\n",
    "# Function to calculate uncertainty (using model predictions)\n",
    "def calculate_uncertainty(model, dataloader, device):\n",
    "    uncertainties = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            uncertainty = -torch.max(probs, dim=1)[0]  # Use negative max probability as uncertainty\n",
    "            uncertainties.extend(uncertainty.cpu().numpy())\n",
    "    return np.array(uncertainties)\n",
    "\n",
    "# Function to apply clustering and select uncertain samples using k-center greedy\n",
    "def select_uncertain_samples(features, uncertainties, n_clusters, n_samples_per_cluster):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(features)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    selected_indices = []\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "        if len(cluster_indices) > 0:\n",
    "            cluster_features = features[cluster_indices]\n",
    "            cluster_uncertainties = uncertainties[cluster_indices]\n",
    "            # Sort by uncertainty and select top n_samples_per_cluster\n",
    "            sorted_indices = cluster_indices[np.argsort(-cluster_uncertainties)[:n_samples_per_cluster]]\n",
    "            selected_indices.extend(sorted_indices)\n",
    "    return selected_indices\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have X_train, y_train, and a trained model\n",
    "features = np.random.rand(1000, 64)  # Example feature data\n",
    "uncertainties = np.random.rand(1000)  # Example uncertainties, replace with actual uncertainties\n",
    "n_clusters = 10\n",
    "n_samples_per_cluster = 5\n",
    "\n",
    "selected_indices = select_uncertain_samples(features, uncertainties, n_clusters, n_samples_per_cluster)\n",
    "\n",
    "# Interactive Labeling\n",
    "def interactive_labeling(images, labels, selected_indices):\n",
    "    label_widgets = [widgets.Dropdown(options=list(set(labels)), description=f'Label {i+1}', value=labels[idx]) for i, idx in enumerate(selected_indices)]\n",
    "    button = widgets.Button(description=\"Submit Labels\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def on_button_clicked(b):\n",
    "        with output:\n",
    "            for i, widget in enumerate(label_widgets):\n",
    "                labels[selected_indices[i]] = widget.value\n",
    "            print(\"Updated labels:\", extract_labels_at_indices(labels, selected_indices))\n",
    "\n",
    "    button.on_click(on_button_clicked)\n",
    "    display(*label_widgets, button, output)\n",
    "\n",
    "# Visualize and label\n",
    "visualize_selected_images(X_train, y_train, selected_indices)\n",
    "interactive_labeling(X_train, y_train, selected_indices)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
