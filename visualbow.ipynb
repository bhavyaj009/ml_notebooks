# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import pairwise_distances
from skimage.feature import hog
from skimage import data, color, feature, exposure
import cv2
import torch
import torchvision
from torch.utils.data import DataLoader, TensorDataset
from lightly import loss, transforms
from lightly.data import LightlyDataset
from lightly.models.modules import heads
import ipywidgets as widgets
from IPython.display import display

# Feature extraction using HOG (Histogram of Oriented Gradients)
def extract_hog_features(images):
    hog_features = []
    for img in images:
        fd = hog(img, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(2, 2), block_norm='L2-Hys', visualize=False)
        hog_features.append(fd)
    return np.array(hog_features)

# Visualize selected images
def visualize_selected_images(images, labels, selected_indices, image_size=(32, 32), grid_shape=(2, 5)):
    fig, axs = plt.subplots(nrows=grid_shape[0], ncols=grid_shape[1], figsize=(15, 6))
    axs = axs.flatten()
    for ax, idx in zip(axs, selected_indices):
        image = images[idx].reshape(image_size[0], image_size[1], 3)
        ax.imshow(image)
        ax.set_title(f"Label: {labels[idx]}")
        ax.axis('off')
    for ax in axs[len(selected_indices):]:
        ax.axis('off')
    plt.tight_layout()
    plt.show()

# k-Center Greedy algorithm for uncertainty sampling
def k_center_greedy(features, n_samples):
    n_points = features.shape[0]
    centers = [np.random.randint(n_points)]
    distances = pairwise_distances(features, features[centers]).flatten()
    for _ in range(1, n_samples):
        new_center = np.argmax(distances)
        centers.append(new_center)
        new_distances = pairwise_distances(features, features[new_center].reshape(1, -1)).flatten()
        distances = np.minimum(distances, new_distances)
    return centers

# Function to calculate uncertainty based on distance to cluster centroids
def calculate_uncertainty(features, centroids):
    distances = pairwise_distances(features, centroids)
    uncertainty = np.min(distances, axis=1)  # Minimum distance to any cluster centroid
    return uncertainty

# Function to apply clustering and select uncertain samples using k-center greedy
def select_uncertain_samples(features, n_clusters, n_samples_per_cluster):
    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(features)
    cluster_labels = kmeans.labels_
    centroids = kmeans.cluster_centers_
    uncertainties = calculate_uncertainty(features, centroids)
    
    selected_indices = []
    for cluster in range(n_clusters):
        cluster_indices = np.where(cluster_labels == cluster)[0]
        if len(cluster_indices) > 0:
            cluster_features = features[cluster_indices]
            cluster_uncertainties = uncertainties[cluster_indices]
            sorted_indices = cluster_indices[np.argsort(-cluster_uncertainties)[:n_samples_per_cluster]]
            selected_indices.extend(sorted_indices)
    return selected_indices

# Example usage with CIFAR-10 data
# Load CIFAR-10 data
from tensorflow.keras.datasets import cifar10
(X_train, y_train), (X_test, y_test) = cifar10.load_data()
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0
y_train = y_train.flatten()
y_test = y_test.flatten()

# Convert images to grayscale
X_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_train])
X_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_test])

# Extract HOG features
train_features = extract_hog_features(X_train_gray)
test_features = extract_hog_features(X_test_gray)

# Apply clustering and select uncertain samples
n_clusters = 10
n_samples_per_cluster = 5
selected_indices = select_uncertain_samples(train_features, n_clusters, n_samples_per_cluster)

# Visualize selected samples
visualize_selected_images(X_train, y_train, selected_indices)

# Interactive Labeling
def interactive_labeling(images, labels, selected_indices):
    label_widgets = [widgets.Dropdown(options=list(set(labels)), description=f'Label {i+1}', value=labels[idx]) for i, idx in enumerate(selected_indices)]
    button = widgets.Button(description="Submit Labels")
    output = widgets.Output()

    def on_button_clicked(b):
        with output:
            for i, widget in enumerate(label_widgets):
                labels[selected_indices[i]] = widget.value
            print("Updated labels:", extract_labels_at_indices(labels, selected_indices))

    button.on_click(on_button_clicked)
    display(*label_widgets, button, output)

# Visualize and label
interactive_labeling(X_train, y_train, selected_indices)
